% Page formatting
\documentclass[11pt]{article}
\usepackage[margin=1in]{geometry}

% Math packages
\usepackage{amsfonts, amsmath, amssymb, amsthm}
\usepackage{mathtools}

% Graphs
\usepackage{tikz}

% Formatting packages
\usepackage{xcolor}
\usepackage[inline,shortlabels]{enumitem}
\usepackage{hyperref} % Links
\hypersetup{colorlinks=true, linkcolor = navyblue, urlcolor=blue}
\usepackage{titlesec} % Title
\usepackage{mdframed} % Boxes
\usepackage[twoside]{fancyhdr} % Header
\usepackage{mathtools}
\usepackage{enumitem}

% Algorithm / Code packages
\usepackage[linesnumbered,ruled,vlined]{algorithm2e}
\usepackage[sanserif,full]{complexity}


\setlength{\headheight}{15pt}

% -------------------------------------- TITLE ------------------------------------------
\title{}
\author{Whitaker Thompson}
\date{\today}
% -------------------------------------- TITLE ------------------------------------------

% Format the section titles
\renewcommand{\thesection}{\Roman{section}}

% Commands
\newcommand{\CC}{\mathbb{C}}
\newcommand{\RR}{\mathbb{R}}
\newcommand{\QQ}{\mathbb{Q}}
\newcommand{\ZZ}{\mathbb{Z}}
\newcommand{\NN}{\mathbb{N}}
\newcommand{\norm}[1]{\left\lVert #1 \right\rVert}
\newcommand{\curlyt}{\mathscr{T}}
\newcommand{\curlyc}{\mathscr{C}}
\newcommand{\curlyb}{\mathscr{B}}
\newcommand{\curlyu}{\mathscr{U}}
\newcommand{\curlyv}{\mathscr{V}}
\newcommand{\im}{\text{im}}
\newcommand{\tr}{\text{tr}}
\newcommand{\inv}[1]{#1^{-1}}
\DeclarePairedDelimiter{\abs}{\lvert}{\rvert}
\newcommand{\sol}{\textbf{Solution. }}
\newtheorem*{lemma}{Lemma}

% EECS 475 Commands
\newcommand{\keyspace}{\ensuremath{\mathcal{K}}}
\newcommand{\msgspace}{\ensuremath{\mathcal{M}}}
\newcommand{\ctspace}{\ensuremath{\mathcal{C}}}
\newcommand{\tagspace}{\ensuremath{\mathcal{T}}}
\newcommand{\idspace}{\ensuremath{\mathcal{ID}}}
\newcommand{\skcgen}{{\sf Gen}} 
\newcommand{\skcenc}{{\sf Enc}}
\newcommand{\skcdec}{{\sf Dec}}
\newcommand{\negl}{\text{negl}}
\newcommand{\bit}{\{0,1\}}
\newcommand{\calD}{\mathcal{D}}
\newcommand{\inner}[2]{\langle #1, #2 \rangle}
\newcommand{\advan}{\textbf{Adv}}
\newcommand{\Ex}{\mathbb{E}}
\newcommand{\argmin}{\text{argmin}}
\newcommand{\argmax}{\text{argmax}}



\begin{document}


%------------------------------------- HEADER --------------------------------------------
%\fancyhead[R]{Whitaker Thompson}
%\fancyhead[L]{Class}
%\fancyhead[C]{\today}
%\fancyfoot[C]{\thepage}
%------------------------------------- HEADER --------------------------------------------

%\maketitle
%\thispagestyle{fancy} % For formatting the title page


% -----------------------------COMMANDS FOR TOC ------------------------------------
%\tableofcontents
%\newpage


%---------------------------------- BEGIN -------------------------------------------
\begin{centering}

{\huge Academic Statement of Purpose}

\smallskip

Whitaker Thompson 

\end{centering}


\noindent\rule{\textwidth}{0.4pt}

I hope to pursue a Ph.D. in theoretical computer science to study discrete optimization, particularly approximation algorithms and hardness of approximation for $\NP$-hard problems. I also enjoy thinking about the interaction of these areas with parameterized algorithms, and establishing lower bound and hardness results for the approximate and parameterized versions of these problems.

With Euiwoong Lee, I studied the Unique Games problem when the constraint graph is a metric graph, i.e.\ a complete graph equipped with a weight that obeys the triangle inequality. The Unique Games problem is central in the theory of hardness of approximation; it is conjectured to admit no $O(1)$-approximation in the general case. This conjecture implies the optimality of approximation algorithms for several canonical $\NP$-hard problems, including \textsc{VertexCover} and \textsc{MaxCut}. Understanding the approximability of the problem on more restricted instances such as ours can give insight into the general case. 

An existing algorithm for the Unique Games problem rounds a solution to a semidefinite programming relaxation of the problem. The quality of the approximation is then dependent on the expansion of the constraint graph. Our initial approach was to try and prove that metric graphs expand well, i.e.\ that the second largest eigenvalue of the normalized adjacency matrix of the graph is bounded above by some constant. I was able to prove a weaker version of this fact, but ultimately switched directions.

In similar problems, where the goal is to assign some labels to vertices to satisfy constraints along edges, an algorithmic paradigm that has been successful is that of using a \emph{pivot}. In these algorithms, a vertex is designated as the pivot, and the label for every vertex in the neighborhood of the pivot is chosen with respect to the constraint along the edge. These algorithms are beautifully simple, and while the choices they make are local, they actually end up leading to good global assignments. This approach has been successful for Unique Games on unweighted complete graphs. To generalize this to metric weighted graphs, we came up with a randomized algorithm that selects a pivot vertex and then rounds a solution to an extended linear programming relaxation of the problem. Our analysis crucially used the triangle inequality and resulted in the first constant-factor approximation algorithm for our problem, which separates our version of the problem from the general case, assuming the Unique Games Conjecture. This project culminated in my senior honors thesis, which I presented just before my graduation in April 2025.

Though our result was substantial, the approximability of our problem was not entirely resolved yet. After my graduation in May 2025, I spent time by myself trying to find a polynomial-time approximation scheme (PTAS) for the problem. I reviewed PTASes for metric versions of graph problems that used existing PTASes on dense versions as a subroutine, and this is where I became acquainted with and interested in the approximability of CSPs. I was drawn to them for their generality, and I continue to actively work toward using them to solve my problem.

Going into my final semester of my undergradute studies, I was completely set on pursuing a career in theoretical computer science research, and I decided to apply to graduate school during the fall of 2025. For the 2025-2026 school year, I accepted a job through Americorps as a math tutor at a high school in Boston for students who needed supplemental instruction. Unfortunately, in late June, I found out that due to funding issues, the job would not be offered for the upcoming school year. I was working a retail job in Ann Arbor for the summer in order to save money for graduate school applications, and I decided to continue working at that job throughout the 2025-2026 school year, which would allow me to support myself financially and to audit some graduate theoretical computer science courses that were being offered at Michigan in the fall of 2025. This has been a great way to continue thinking about algorithms and familiarizing myself with different areas of theory.

One of the courses I have been auditing this year is a special topics class on parameterized and fast exponential algorithms. I previously had seen parameterized algorithms in a graph algorithms course I took during my final undergraduate semester, and the course I am auditing is being taught by a professor who mainly works in approximation algorithms, so there was more of a focus on the interaction of parameterized algorithms with approximation algorithms. I have become interested in whether or not using both parameterization \emph{and} approximation can give an advantage for problems that each individual subarea suggest is hard. In pursuit of this, for my final project in the class, I am preparing a talk on a recent paper that surveys the parameterized approximability of the clique problem in order to acquaint myself with the existing literature.

I am particularly interested in working with Professor Konstantin Makarychev on approximation algorithms for $\NP$-hard problems. His recent work of proving approximability results of CSPs would be a natural progression of my recent research interests in the area. I could also continue to explore what I started in my thesis, that is, using higher-order continuous programming relaxations to come up with viable approximation algorithms for computationally hard problems. Working with Samir Khuller would also allow me to explore this path, with much of my existing research having been in problems closely related to clustering and the various approximation techniques that are used to cope with their hardness. 

\end{document}
